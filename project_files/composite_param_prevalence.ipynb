{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Prevalence\n",
    "This notebook calculates the prevalence of the model parameters in the variety trial corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify models\n",
    "models = ['aquacrop', 'dssat', 'genericdescriptive',\n",
    "          'rodekoning', 'rotomgro', 'stics']\n",
    "\n",
    "# Set temporal precision scores\n",
    "temp_order = {'time': 5, 'date': 4, 'frequency': 3, 'range': 2, 'static': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_models(model):\n",
    "\t# load param_df\n",
    "\tparam_df = pd.read_csv(f'scoring_sheets/reviewed/composite_{model}_comparison_reviewed.csv')\n",
    "\t# copy param_df\n",
    "\tfill_df = param_df.copy()\n",
    "\t# drop rows where score is not 2\n",
    "\tfill_df = fill_df[fill_df['score'] == 2]\n",
    "\t# drop unnecessary columns\n",
    "\tfill_df.drop(columns=['t_temp', 'score', 'm_param', 't_param', 'situational', 'importance'], inplace=True)\n",
    "\t# keep only rows with the same universal term with the highest fraction\n",
    "\tfill_df = fill_df.sort_values('fraction', ascending=False).drop_duplicates('universal_term').sort_index()\n",
    "\t# get a list of the parent_parameters\n",
    "\tparent_params = fill_df['parent_parameter'].unique()\n",
    "\t# for each parent parameter, drop all rows but the one with the highest fraction\n",
    "\tfor parent_param in parent_params:\n",
    "\t\tparent_df = fill_df[fill_df['parent_parameter'] == parent_param]\n",
    "\t\tmax_fraction = parent_df['fraction'].max()\n",
    "\t\tfill_df = fill_df.drop(parent_df[parent_df['fraction'] < max_fraction].index)\n",
    "\t\t# if there is a tie for max_fraction, drop all but the first\n",
    "\t\tfill_df = fill_df.drop(parent_df[parent_df['fraction'] == max_fraction].index[1:])\n",
    "\t# if parent parameter is not nan, replace index with parent parameter\n",
    "\tfill_df['universal_term'] = fill_df['universal_term'].where(fill_df['parent_parameter'].isnull(), fill_df['parent_parameter'])\n",
    "\t# reset the index as a new index\n",
    "\tfill_df.reset_index(drop=True, inplace=True)\n",
    "\t# drop columns parent parameter, fraction, m_temp, t_temp, score, m_param, t_param\n",
    "\tfill_df.drop(columns=['parent_parameter'], inplace=True)\n",
    "\t# rename m_temp to temporality\n",
    "\tfill_df.rename(columns={'m_temp': 'temporality'}, inplace=True)\n",
    "\treturn fill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dssat_df = process_models('dssat')\n",
    "aquacrop_df = process_models('aquacrop')\n",
    "genericdescriptive_df = process_models('genericdescriptive')\n",
    "rodekoning_df = process_models('rodekoning')\n",
    "rotomgro_df = process_models('rotomgro')\n",
    "stics_df = process_models('stics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs = {'dssat': dssat_df, 'aquacrop': aquacrop_df, 'genericdescriptive': genericdescriptive_df, 'rodekoning': rodekoning_df, 'rotomgro': rotomgro_df, 'stics': stics_df}\n",
    "# Step 1: Combine all unique rows from the processed dataframes\n",
    "all_rows = pd.concat([df[['universal_term', 'domain', 'temporality', 'fraction']] for df in processed_dfs.values()], ignore_index=True)\n",
    "prev_df = all_rows.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Add columns for each model, initialized as NaN\n",
    "for model in processed_dfs.keys():\n",
    "    prev_df[model] = np.nan\n",
    "\n",
    "# Step 3: Mark `True` for rows present in each model's dataframe\n",
    "for model, model_df in processed_dfs.items():\n",
    "    # Merge prev_df with the model dataframe to find exact matches\n",
    "    matches = prev_df.merge(model_df[['universal_term', 'domain', 'temporality', 'fraction']], \n",
    "                            on=['universal_term', 'domain', 'temporality', 'fraction'], \n",
    "                            how='inner')\n",
    "    \n",
    "    # Find indices of matched rows\n",
    "    match_indices = prev_df.index[\n",
    "        prev_df.set_index(['universal_term', 'domain', 'temporality', 'fraction']).index.isin(\n",
    "            matches.set_index(['universal_term', 'domain', 'temporality', 'fraction']).index\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Update the corresponding model column to True\n",
    "    prev_df.loc[match_indices, model] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129 entries, 0 to 128\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   universal_term      129 non-null    object \n",
      " 1   domain              129 non-null    object \n",
      " 2   temporality         121 non-null    object \n",
      " 3   fraction            129 non-null    float64\n",
      " 4   dssat               88 non-null     object \n",
      " 5   aquacrop            32 non-null     object \n",
      " 6   genericdescriptive  6 non-null      object \n",
      " 7   rodekoning          8 non-null      object \n",
      " 8   rotomgro            8 non-null      object \n",
      " 9   stics               62 non-null     object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 10.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prev_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prev_df\n",
    "prev_df.to_csv('prevalence/composite_param_prevalence.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload final prev_df\n",
    "prev_df = pd.read_csv('prevalence/final_inspected/composite_param_prevalence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   structural characteristics  0 non-null      object\n",
      " 1   ground cover                0 non-null      object\n",
      " 2   soil                        0 non-null      object\n",
      " 3   field history               0 non-null      object\n",
      " 4   fertilizer                  0 non-null      object\n",
      " 5   weeds, pests, diseases      0 non-null      object\n",
      " 6   transplanting               0 non-null      object\n",
      " 7   harvesting                  0 non-null      object\n",
      " 8   yield                       0 non-null      object\n",
      " 9   irrigation                  0 non-null      object\n",
      " 10  location                    0 non-null      object\n",
      " 11  spacing                     0 non-null      object\n",
      " 12  pruning                     0 non-null      object\n",
      " 13  seeding                     0 non-null      object\n",
      " 14  plot                        0 non-null      object\n",
      " 15  tillage                     0 non-null      object\n",
      " 16  trellis                     0 non-null      object\n",
      " 17  tunnel                      0 non-null      object\n",
      "dtypes: object(18)\n",
      "memory usage: 124.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create a df with columns for each unique domain\n",
    "domain_df = pd.DataFrame(columns=prev_df['domain'].unique())\n",
    "print(domain_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain\n",
      "fertilizer                     7\n",
      "field history                  5\n",
      "ground cover                   2\n",
      "harvesting                     3\n",
      "irrigation                     5\n",
      "location                       1\n",
      "plot                           1\n",
      "pruning                        2\n",
      "seeding                        3\n",
      "soil                          26\n",
      "spacing                        3\n",
      "structural characteristics    36\n",
      "tillage                        3\n",
      "transplanting                  7\n",
      "trellis                        1\n",
      "tunnel                         3\n",
      "weeds, pests, diseases         7\n",
      "yield                          3\n",
      "Name: universal_term, dtype: int64\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "# add a row for the number of universal terms per domain without using append or concat\n",
    "n_params = prev_df.groupby('domain')['universal_term'].nunique()\n",
    "print(n_params)\n",
    "# sum\n",
    "sum = n_params.sum()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with columns for each unique domain\n",
    "domain_df = pd.DataFrame(columns=prev_df['domain'].unique())\n",
    "# add a row for the number of universal terms per domain without using append or concat\n",
    "n_params = prev_df.groupby('domain')['universal_term'].nunique()\n",
    "# add a row for the average fraction per domain\n",
    "f_params = prev_df.groupby('domain')['fraction'].mean()\n",
    "# add a row for the number of 0s per domain\n",
    "n_0_params = prev_df.groupby('domain')['fraction'].apply(lambda x: (x == 0).sum())\n",
    "# add a row for the fraction of 0s per domain\n",
    "f_0_params = prev_df.groupby('domain')['fraction'].apply(lambda x: (x == 0).mean())\n",
    "# add the rows to domain_df\n",
    "# add a metric column that states each row's metric\n",
    "metrics = ['n_params', 'f_params', 'n_0_params', 'f_0_params']\n",
    "metric_values = [n_params, f_params, n_0_params, f_0_params]\n",
    "# Manually construct the rows\n",
    "for metric, values in zip(metrics, metric_values):\n",
    "    new_row = pd.Series(values, name=metric)\n",
    "    domain_df.loc[metric] = new_row\n",
    "    \n",
    "\n",
    "# Add a metric column\n",
    "domain_df['metric'] = metrics\n",
    "\n",
    "# Reset the index for a clean DataFrame\n",
    "domain_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   structural characteristics  ground cover       soil  field history  \\\n",
      "0                   36.000000           2.0  26.000000          5.000   \n",
      "1                    0.008649           0.0   0.063077          0.028   \n",
      "2                   33.000000           2.0  21.000000          4.000   \n",
      "3                    0.891892           1.0   0.807692          0.800   \n",
      "\n",
      "   fertilizer  weeds, pests, diseases  transplanting  harvesting     yield  \\\n",
      "0    7.000000                7.000000       7.000000    3.000000  3.000000   \n",
      "1    0.638571                0.157143       0.197143    0.363333  0.523333   \n",
      "2    2.000000                2.000000       5.000000    1.000000  1.000000   \n",
      "3    0.285714                0.285714       0.714286    0.333333  0.333333   \n",
      "\n",
      "   irrigation  location   spacing  pruning  seeding  plot  tillage  trellis  \\\n",
      "0       5.000      1.00  3.000000     2.00   3.0000   1.0      3.0     1.00   \n",
      "1       0.332      0.94  0.530000     0.08   0.2275   0.0      0.0     0.03   \n",
      "2       2.000      0.00  1.000000     1.00   3.0000   1.0      3.0     0.00   \n",
      "3       0.400      0.00  0.333333     0.50   0.7500   1.0      1.0     0.00   \n",
      "\n",
      "     tunnel      metric  \n",
      "0  3.000000    n_params  \n",
      "1  0.153333    f_params  \n",
      "2  1.000000  n_0_params  \n",
      "3  0.333333  f_0_params  \n"
     ]
    }
   ],
   "source": [
    "print(domain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "domain_df.to_csv('prevalence/final_inspected/composite_prevalence_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of static universal terms for each domain\n",
    "static_df = prev_df[prev_df['temporality'] == 'static']\n",
    "n_static_params = static_df.groupby('domain')['universal_term'].nunique()\n",
    "# get the number of date universal terms for each domain\n",
    "date_df = prev_df[prev_df['temporality'] == 'date']\n",
    "n_date_params = date_df.groupby('domain')['universal_term'].nunique()\n",
    "# columns\n",
    "cols = ['n_static_params', 'n_date_params']\n",
    "# combine the two dfs\n",
    "static_date_df = pd.concat([n_static_params, n_date_params], axis=1)\n",
    "static_date_df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            n_static_params  n_date_params\n",
      "domain                                                    \n",
      "fertilizer                                6              1\n",
      "field history                             5              0\n",
      "ground cover                              2              0\n",
      "harvesting                                2              1\n",
      "irrigation                                4              1\n",
      "location                                  1              0\n",
      "plot                                      1              0\n",
      "pruning                                   1              1\n",
      "seeding                                   1              3\n",
      "soil                                     22              4\n",
      "spacing                                   3              0\n",
      "structural characteristics                1             36\n",
      "tillage                                   2              1\n",
      "transplanting                             5              2\n",
      "trellis                                   1              0\n",
      "tunnel                                    2              1\n",
      "weeds, pests, diseases                    3              4\n",
      "yield                                     0              3\n"
     ]
    }
   ],
   "source": [
    "# convert NaNs to 0\n",
    "static_date_df.fillna(0, inplace=True)\n",
    "# convert to int\n",
    "static_date_df = static_date_df.astype(int)\n",
    "print(static_date_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "static_date_df.to_csv('prevalence/final_inspected/composite_temp_params_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with columns for each unique temporality\n",
    "temp_df = pd.DataFrame(columns=prev_df['temporality'].unique())\n",
    "# add a row for the number of universal terms per temporality without using append or concat\n",
    "n_params = prev_df.groupby('temporality')['universal_term'].nunique()\n",
    "# add a row for the average fraction per temporality\n",
    "f_params = prev_df.groupby('temporality')['fraction'].mean()\n",
    "# add a row for the number of 0s per temporality\n",
    "n_0_params = prev_df.groupby('temporality')['fraction'].apply(lambda x: (x == 0).sum())\n",
    "# add a row for the fraction of 0s per temporality\n",
    "f_0_params = prev_df.groupby('temporality')['fraction'].apply(lambda x: (x == 0).mean())\n",
    "# add the rows to temp_df\n",
    "# add a metric column that states each row's metric\n",
    "metrics = ['n_params', 'f_params', 'n_0_params', 'f_0_params']\n",
    "metric_values = [n_params, f_params, n_0_params, f_0_params]\n",
    "# Manually construct the rows\n",
    "for metric, values in zip(metrics, metric_values):\n",
    "\tnew_row = pd.Series(values, name=metric)\n",
    "\ttemp_df.loc[metric] = new_row\n",
    "\n",
    "# Add a metric column\n",
    "temp_df['metric'] = metrics\n",
    "\n",
    "# Reset the index for a clean DataFrame\n",
    "temp_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date     static      metric\n",
      "0  57.000000  62.000000    n_params\n",
      "1   0.112069   0.176774    f_params\n",
      "2  42.000000  41.000000  n_0_params\n",
      "3   0.724138   0.661290  f_0_params\n"
     ]
    }
   ],
   "source": [
    "print(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "temp_df.to_csv('prevalence/final_inspected/composite_temp_prevalence_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
